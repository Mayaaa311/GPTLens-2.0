[llama3]
n_gpu_layers = -1
n_ctx = 4096
temperature=0.5

[llama2]
n_gpu_layers = -1
n_ctx = 4096
model_path = "models/llama-2-7b.Q5_K_M.gguf"

[codellama]
n_gpu_layers = -1
n_ctx = 4096
temperature=0

[codeqwen]
n_gpu_layers = -1
n_ctx = 4096
temperature=0

[deepseek-coder-v2]
n_gpu_layers = -1
n_ctx = 4096
temperature=0.5